{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([  [1,2,3,4], [5,6,7,8],[1,4,9,6],[1,4,8,9] ]) # as it is an array we made array of array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the data with mean 0 and std 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denim/anaconda3/envs/ana41py35/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "standard_data = preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " mean of data =  [2.   4.   6.75 6.75]\n",
      "\n",
      " mean of standard_data=  [-5.55111512e-17  0.00000000e+00  2.77555756e-17  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n mean of data = \",data.mean(axis= 0) )\n",
    "print(\"\\n mean of standard_data= \",standard_data.mean(axis= 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " standard deviation =  [1.73205081 1.41421356 2.27760839 1.92028644]\n",
      "\n",
      " standard deviation of standard_data =  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print( \"\\n standard deviation = \" , data.std(axis=0))\n",
    "print( \"\\n standard deviation of standard_data = \" , standard_data.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale the data with to squeeze it between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denim/anaconda3/envs/ana41py35/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "data_scaling = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "scaled_data = data_scaling.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " scaled_data  =  [[0.         0.         0.         0.        ]\n",
      " [1.         1.         0.66666667 0.8       ]\n",
      " [0.         0.5        1.         0.4       ]\n",
      " [0.         0.5        0.83333333 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n scaled_data  = \", scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = preprocessing.normalize(data,norm= 'l1') # and with l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " normalized_data =  [[0.1        0.2        0.3        0.4       ]\n",
      " [0.19230769 0.23076923 0.26923077 0.30769231]\n",
      " [0.05       0.2        0.45       0.3       ]\n",
      " [0.04545455 0.18181818 0.36363636 0.40909091]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n normalized_data = \", normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_data = preprocessing.binarize(data, threshold=5)  #.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Binarized data =  [[0 0 0 0]\n",
      " [0 1 1 1]\n",
      " [0 0 1 1]\n",
      " [0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Binarized data = \", binarized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded vector = [[1. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denim/anaconda3/envs/ana41py35/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([[1, 2, 1, 12], [1, 3, 5, 3], [1, 3, 2, 12], [1, 2, 4,\n",
    "3]])\n",
    "encoded_vector = encoder.transform([[1, 1, 1, 1]]).toarray()\n",
    "print (\"\\nEncoded vector =\", encoded_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_classes = ['US', 'Russia', 'India', 'China', 'US', 'Japan', 'US', 'Ausrallia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class mapping:\n",
      "Ausrallia --> 0\n",
      "China --> 1\n",
      "India --> 2\n",
      "Japan --> 3\n",
      "Russia --> 4\n",
      "US --> 5\n"
     ]
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(input_classes)\n",
    "print(\"\\nClass mapping:\")\n",
    "for i, item in enumerate(label_encoder.classes_):\n",
    " print(item, \"-->\", i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "it start from back to label the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels = ['US', 'Russia', 'China']\n",
      "Encoded labels = [5, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "# get back the value of a perticular class\n",
    "labels = ['US', 'Russia', 'China']\n",
    "encoded_labels = label_encoder.transform(labels)\n",
    "print (\"\\nLabels =\", labels )\n",
    "print (\"Encoded labels =\", list(encoded_labels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded labels = [2, 1, 0, 3, 1]\n",
      "Decoded labels = ['India', 'China', 'Ausrallia', 'Japan', 'China']\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = [2, 1, 0, 3, 1]\n",
    "decoded_labels = label_encoder.inverse_transform(encoded_labels)\n",
    "print (\"\\nEncoded labels =\", encoded_labels)\n",
    "print (\"Decoded labels =\", list(decoded_labels) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
